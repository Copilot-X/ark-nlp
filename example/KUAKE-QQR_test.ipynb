{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import jieba\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from ark_nlp.nn import Ernie\n",
    "from ark_nlp.dataset import TMDataset\n",
    "from ark_nlp.factory.task import TMTask\n",
    "from ark_nlp.factory.optimizer import get_default_bert_optimizer\n",
    "from ark_nlp.processor.tokenizer.transfomer import PairTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目录地址\n",
    "\n",
    "train_data_path = '../data/source_datasets/KUAKE-QQR/KUAKE-QQR_train.json'\n",
    "dev_data_path = '../data/source_datasets/KUAKE-QQR/KUAKE-QQR_dev.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、数据读入与处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = pd.read_json(train_data_path)\n",
    "train_data_df = (train_data_df\n",
    "                 .rename(columns={'query1': 'text_a', 'query2': 'text_b'})\n",
    "                 .loc[:,['text_a', 'text_b', 'label']])\n",
    "\n",
    "dev_data_df = pd.read_json(dev_data_path)\n",
    "dev_data_df = dev_data_df[dev_data_df['label'] != \"NA\"]\n",
    "dev_data_df = (dev_data_df\n",
    "                 .rename(columns={'query1': 'text_a', 'query2': 'text_b'})\n",
    "                 .loc[:,['text_a', 'text_b', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_train_dataset = TMDataset(train_data_df)\n",
    "tm_dev_dataset = TMDataset(dev_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 词典创建和生成分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以先创建词典，再加载入分词器\n",
    "# 也可以使用分词器自动加载\n",
    "# bert_vocab = transformers.AutoTokenizer.from_pretrained('nghuyong/ernie-1.0')\n",
    "# tokenizer = TransfomerTokenizer(bert_vocab, max_seq_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PairTokenizer(vocab='nghuyong/ernie-1.0', max_seq_len=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. ID化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_train_dataset.convert_to_ids(tokenizer)\n",
    "tm_dev_dataset.convert_to_ids(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 二、模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 模型参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "bert_config = BertConfig.from_pretrained('nghuyong/ernie-1.0', \n",
    "                                         num_labels=len(tm_train_dataset.cat2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 模型创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_module = Ernie.from_pretrained('nghuyong/ernie-1.0',\n",
    "                                  config=bert_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 三、任务构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 任务参数和必要部件设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置运行次数\n",
    "num_epoches = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_default_bert_optimizer(dl_module) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 任务创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TMTask(dl_module, optimizer, 'ce', cuda_device=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(tm_train_dataset, \n",
    "          tm_dev_dataset,\n",
    "          lr=2e-5,\n",
    "          epochs=5, \n",
    "          batch_size=batch_size\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 四、模型验证与保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ark_nlp.factory.predictor import TMPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_predictor_instance = TMPredictor(model.module, tokenizer, tm_train_dataset.cat2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_predictor_instance.predict_one_sample(['女生第一次后大姨妈迟到', '第一次会不会影响大姨妈推迟'], \n",
    "                                         return_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Batch模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df = pd.read_json('../data/source_datasets/KUAKE-QQR/KUAKE-QQR_train.json')\n",
    "test_data_df = (test_data_df\n",
    "                 .rename(columns={'query1': 'text_a', 'query2': 'text_b'})\n",
    "                 .loc[:,['text_a', 'text_b', 'label']])\n",
    "\n",
    "\n",
    "tm_test_dataset = TMDataset(test_data_df, categories=tm_train_dataset.categories, is_test=True)\n",
    "tm_test_dataset.convert_to_ids(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = tm_predictor_instance.predict_batch(tm_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 五、模型测试报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 基本功能测试 通过\n",
    "2. one sample predict 通过\n",
    "3. batch predict  通过"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "king_nlp",
   "language": "python",
   "name": "king_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
