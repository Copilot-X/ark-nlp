{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import jieba\n",
    "import torch\n",
    "import pickle\n",
    "import codecs\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from ark_nlp.model.re.prgc_bert import PRGCBert\n",
    "from ark_nlp.model.re.prgc_bert import PRGCBertConfig\n",
    "from ark_nlp.model.re.prgc_bert import Dataset\n",
    "from ark_nlp.model.re.prgc_bert import Task\n",
    "from ark_nlp.model.re.prgc_bert import get_default_model_optimizer\n",
    "from ark_nlp.model.re.prgc_bert import Tokenizer\n",
    "from ark_nlp.factory.loss_function import CasrelLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目录地址\n",
    "\n",
    "train_data_path = '../data/source_datasets/CMeIE/CMeIE_train.json'\n",
    "dev_data_path = '../data/source_datasets/CMeIE/CMeIE_dev.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = []\n",
    "\n",
    "with codecs.open(train_data_path, mode='r', encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "    for index_, line_ in enumerate(lines):\n",
    "        record_ = {}\n",
    "        line_ = json.loads(line_.strip())\n",
    "        record_['text'] = line_['text']\n",
    "        record_['label'] = []\n",
    "        for triple_ in line_['spo_list']:\n",
    "            record_['label'].append([\n",
    "                triple_['subject'],\n",
    "                record_['text'].index(triple_['subject']),\n",
    "                record_['text'].index(triple_['subject'])+ len(triple_['subject']) - 1,\n",
    "                triple_['predicate'] + '@' + triple_['object_type']['@value'],\n",
    "                triple_['object']['@value'],\n",
    "                record_['text'].index(triple_['object']['@value']),\n",
    "                record_['text'].index(triple_['object']['@value']) + len(triple_['object']['@value']) - 1,\n",
    "            ])\n",
    "        train_data_list.append(record_)\n",
    "\n",
    "train_data_df = pd.DataFrame(train_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_list = []\n",
    "counter = 0\n",
    "with codecs.open(dev_data_path, mode='r', encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "    for index_, line_ in enumerate(lines):\n",
    "        record_ = {}\n",
    "        line_ = json.loads(line_.strip())\n",
    "        record_['text'] = line_['text']\n",
    "        record_['label'] = []\n",
    "        for triple_ in line_['spo_list']:\n",
    "            record_['label'].append([\n",
    "                triple_['subject'],\n",
    "                record_['text'].index(triple_['subject']),\n",
    "                record_['text'].index(triple_['subject'])+ len(triple_['subject']) - 1,\n",
    "                triple_['predicate'] + '@' + triple_['object_type']['@value'],\n",
    "                triple_['object']['@value'],\n",
    "                record_['text'].index(triple_['object']['@value']),\n",
    "                record_['text'].index(triple_['object']['@value']) + len(triple_['object']['@value']) - 1,\n",
    "            ])\n",
    "            counter += 1\n",
    "        dev_data_list.append(record_)\n",
    "        \n",
    "dev_data_df = pd.DataFrame(dev_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_train_dataset = Dataset(train_data_df, is_retain_dataset=True)\n",
    "re_dev_dataset = Dataset(dev_data_df,\n",
    "                         categories = re_train_dataset.categories,\n",
    "                         is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 词典创建和生成分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab='nghuyong/ernie-1.0', max_seq_len=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. ID化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_train_dataset.convert_to_ids(tokenizer)\n",
    "re_dev_dataset.convert_to_ids(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 二、模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 模型参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = PRGCBertConfig.from_pretrained('nghuyong/ernie-1.0',\n",
    "                                               num_labels=len(re_train_dataset.cat2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 模型创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nghuyong/ernie-1.0 were not used when initializing PRGCBert: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing PRGCBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PRGCBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PRGCBert were not initialized from the model checkpoint at nghuyong/ernie-1.0 and are newly initialized: ['sequence_tagging_sub.linear.weight', 'sequence_tagging_sub.linear.bias', 'sequence_tagging_sub.hidden2tag.weight', 'sequence_tagging_sub.hidden2tag.bias', 'sequence_tagging_obj.linear.weight', 'sequence_tagging_obj.linear.bias', 'sequence_tagging_obj.hidden2tag.weight', 'sequence_tagging_obj.hidden2tag.bias', 'sequence_tagging_sum.linear.weight', 'sequence_tagging_sum.linear.bias', 'sequence_tagging_sum.hidden2tag_sub.weight', 'sequence_tagging_sum.hidden2tag_sub.bias', 'sequence_tagging_sum.hidden2tag_obj.weight', 'sequence_tagging_sum.hidden2tag_obj.bias', 'rel_judgement.linear.weight', 'rel_judgement.linear.bias', 'rel_judgement.hidden2tag.weight', 'rel_judgement.hidden2tag.bias', 'rel_embedding.weight', 'global_corres.linear.weight', 'global_corres.linear.bias', 'global_corres.hidden2tag.weight', 'global_corres.hidden2tag.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "dl_module = PRGCBert.from_pretrained('nghuyong/ernie-1.0',\n",
    "                                       config=bert_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 三、任务构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 任务参数和必要部件设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_default_model_optimizer(dl_module) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 任务创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Task(dl_module, optimizer, None, cuda_device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 101/3282 [00:16<08:26,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99/3282],train loss is:0.907108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 201/3282 [00:32<08:09,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199/3282],train loss is:0.688802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 301/3282 [00:47<07:55,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[299/3282],train loss is:0.580935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 399/3282 [01:03<07:39,  6.28it/s]"
     ]
    }
   ],
   "source": [
    "model.fit(re_train_dataset,\n",
    "          re_dev_dataset,\n",
    "          epochs=30, \n",
    "          batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 四、模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ark_nlp.model.re.prgc_bert import Predictor\n",
    "\n",
    "prgc_re_predictor_instance = Predictor(model.module, tokenizer, re_train_dataset.cat2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '骨性关节炎@在其他关节（如踝关节和腕关节），骨性关节炎比较少见，并且一般有潜在的病因（如结晶性关节病、创伤）'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prgc_re_predictor_instance.predict_one_sample(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "king_nlp",
   "language": "python",
   "name": "king_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
